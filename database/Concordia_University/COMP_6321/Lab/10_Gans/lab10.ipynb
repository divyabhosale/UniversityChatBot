{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 - Generative Adversarial Networks (GANs)\n",
    "\n",
    "In this lab you'll use [PyTorch](https://pytorch.org/) to train a *generative adversarial network* on synthetic data. Here is the original publication that introduced GANs:\n",
    "\n",
    "* Goodfellow et al. **Generative Adversarial Nets**, NeurIPS 2014 ([PDF](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf))\n",
    "\n",
    "GANs will be covered in lecture. Lab 10 introduces the basics and provides enough starter code to try GANs out for yourself.\n",
    "\n",
    "**What are GANs?**\n",
    "\n",
    "GANs are a type of *generative* model. That means that, at the very least, we can generate samples from the model after it's trained; if training went well, those samples should qualitatively resemble the data that we used to train the generative model.\n",
    "\n",
    "You have already trained a generative model: the GMMs in Lab 3. However, GANs are based on neural networks and are more flexible.\n",
    "\n",
    "If we sample from an untrained GAN, we get useless random noise. The same is true of sampling from an untrained GMM.\n",
    "\n",
    "If we sample from a *trained* GAN, we get data that qualitatively resembles the training data. Again, this is similar to training a GMM, except GANs don't assume the training data is a mixture of Gaussians.\n",
    "\n",
    "**What makes GANs \"adversarial\"?**\n",
    "\n",
    "GANs are trained according to a very intuitive criterion:\n",
    "\n",
    "<blockquote>If the samples drawn from a GAN are <em>indistinguishable</em> from the real data, then they are good samples!\n",
    "</blockquote>\n",
    "\n",
    "*The GAN training objective therefore aims to \"minimize distinguishability.\"* It is of course possible to just memorize the training data, but that is a trivial kind of overfitting.\n",
    "\n",
    "In the GAN training setup, distinguishability is measured by the degree to which a second model, the *discriminator*, is able to classify real versus fake (generated) data. If the discriminator model cannot tell the difference between real and fake, then it must mean the samples we draw from the generator (the GAN) are realistic.\n",
    "\n",
    "The discriminator and generator are thus in competition, as adversaries:\n",
    "* the generator's weights are being adjusted to better \"fool\" the discriminator, tricking it into classifying fake data as \"real.\"\n",
    "* the discriminator's weights are being adjusted to better distinguish (classify) the generator's data as \"fake.\"\n",
    "\n",
    "Once the training is complete, the discriminator is typically thrown away&mdash;its sole job is to provide a constant \"challenge\" to the generator throughout the generator's training process.\n",
    "\n",
    "**How is GAN training formulated?**\n",
    "\n",
    "The problem setup is as follows:\n",
    "* You are given training samples $\\{\\mathbf{x}_1, \\ldots, \\mathbf{x}_N\\}$ with $\\mathbf{x}_i \\in \\mathbb{R}^M$ that represent \"real\" data, for example hand-written digits.\n",
    "* Your goal is to train the weights $\\mathbf{w}$ of a generative model $G_\\mathbf{w} : \\mathbb{R}^K \\rightarrow \\mathbb{R}^M$ so that it can transform samples $\\mathbf{z} \\in \\mathbb{R}^K$ from a standard distribution (*e.g.* uniform, normal) into points $\\mathbf{\\tilde{x}} \\in \\mathbb{R}^M$ that are indistinguishable from the real data.\n",
    "* Distinguishability is measured by a discriminator model $D_\\mathbf{w} : \\mathbb{R}^M \\rightarrow \\mathbb{R}$ that takes either a real $\\mathbf{x}_i$ or a fake $\\mathbf{\\tilde{x}}$ sample as input and classifies it as real (1) or fake (0); the discriminator has its own distinct weights $\\mathbf{w}$ that need to be continually trained to \"keep up\" with improvements to the generator $G$.\n",
    "\n",
    "Therefore, the training loop should try to achieve three things:\n",
    "1. Train $D$ to predict \"real\" ($\\hat{y}=1$) when evaluating $\\hat{y} = D(\\mathbf{x}_i)$ for any real training point $\\mathbf{x}_i$.\n",
    "2. Train $D$ to predict \"fake\" ($\\hat{y}=0$) when evaluating $\\hat{y} = D(\\mathbf{\\tilde{x}})$ for any fake data point $\\mathbf{\\tilde{x}} = G(\\mathbf{z})$.\n",
    "3. Train $G$ to make $D$ predict \"real\" ($\\hat{y}=1$) when evaluating $\\hat{y} = D(\\mathbf{\\tilde{x}})$ for any fake data point $\\mathbf{\\tilde{x}} = G(\\mathbf{z})$.\n",
    "\n",
    "The training scheme is \"adversarial\" because the 2nd and 3rd items are competing objectives, *i.e.* the generator and discriminator are \"fighting\" over whether to predict $1$ (real) or $0$ (fake) when the discriminator classifies a fake data point.\n",
    "\n",
    "\n",
    "**Run the code cell below** to import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time      # for sleep\n",
    "import IPython   # for display, clear_output\n",
    "np.set_printoptions(precision=3, suppress=True)  # Print array values as 0.0023 instead of 2.352e-3\n",
    "torch.set_printoptions(precision=3, sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the exercises will ask you to generate a plot that keeps updating as your GAN is trained.\n",
    "\n",
    "**Run the code cell below** to view a demo of how to **animate a plot**. You can use this code as a reference for how to animate your plots later in the lab. <span style=\"color:red\">Note that you cannot also use the *print* function in a loop where you also update the plot.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1, 21):\n",
    "    \n",
    "    # Clear the current figure's axes\n",
    "    plt.gca().cla()\n",
    "    \n",
    "    # Generate the plot\n",
    "    xvals = np.linspace(-1, 1, i)\n",
    "    plt.plot(xvals, xvals**2, '.-r')         # Plot range x^2 over [-1,1] with i steps\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.title('Using %d steps' % i)\n",
    "    \n",
    "    # Replace the old plot with the new one\n",
    "    IPython.display.display(plt.gcf())       # Tell Jupyter to show Matplotlib's current figure\n",
    "    IPython.display.clear_output(wait=True)  # Tell Jupyter to clear whatever it's currently showing\n",
    "    time.sleep(0.02)                         # Small delay to slow animation (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the code cell below** to define a plotting function that is useful for visualizing the weights of neural networks and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1lim = (-4, 4)\n",
    "x2lim = (-4, 4)\n",
    "\n",
    "def plot_discriminator(discriminator):\n",
    "    \"\"\"Plot the class probabilities of the discriminator (red: fake, blue: real).\"\"\"\n",
    "    x1, x2 = torch.meshgrid(torch.linspace(*x1lim, 100), torch.linspace(*x2lim, 100))\n",
    "    X = torch.cat([x1.t().reshape(-1, 1), x2.t().reshape(-1, 1)], 1)\n",
    "    y = torch.sigmoid(discriminator(X))\n",
    "    y = y.view(x1.shape).detach()\n",
    "    plt.imshow(1-y, extent=x1lim+x2lim, origin='lower', vmin=0, vmax=1, cmap='bwr', alpha=0.25)\n",
    "    if y.min() < 0.5 and y.max() > 0.5:\n",
    "        plt.contour(x1.t(), x2.t(), y, levels=[0.5], colors='k', linewidths=1, alpha=0.15)\n",
    "    plt.xlim(*x1lim)\n",
    "    plt.ylim(*x2lim)\n",
    "    plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 1. Learn how a GAN works\n",
    "\n",
    "Exercise 1.1&ndash;1.5 ask you to generate a synthetic training set, then to train a GAN to mimick your synthetic data using the existing starter code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 1.1 &mdash; Write a function to sample the training set $\\{\\mathbf{x}_i\\}_{i=1}^{N}$\n",
    "\n",
    "You are given a synthetic training set and must write a function that returns a random subsample. The function you write will be by the GAN training loop.\n",
    "\n",
    "**Run the code cell below** to first define a full synthetic training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)  # Make cell output reproducible\n",
    "W_real = torch.tensor([[1.5, 0.0], [0.0, 3.0]])\n",
    "b_real = torch.tensor([-3.0,  -2.0])\n",
    "X_real = torch.rand((1000, 2)) @ W_real + b_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement the *sample_real_data* function.** Use **[torch.randint](https://pytorch.org/docs/1.2.0/torch.html?highlight=randint#torch.randint)** in your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_real_data(batch_size):\n",
    "    \"\"\"\n",
    "    Returns batch_size samples randomly selected from X_real, with replacement.\n",
    "    The resulting array has shape (batch_size, 2).\n",
    "    \"\"\"\n",
    "    # Your code here. Aim for 1-3 lines.\n",
    "    b = torch.randint(0, len(X_real), size=(batch_size,))\n",
    "    return X_real[b]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your answer** by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks good!\n"
     ]
    }
   ],
   "source": [
    "_X = sample_real_data(5)\n",
    "assert isinstance(_X, torch.FloatTensor), \"Expected a tensor of dtype float32.\"\n",
    "assert _X.shape == (5, 2), \"Expected tensor of shape (batch_size, 2).\"\n",
    "for _x in _X:\n",
    "    assert torch.all(_x == X_real, 1).sum() == 1, \"Expected each sample in batch to come from X_real\"\n",
    "assert not torch.equal(_X, sample_real_data(5)), \"Expected different samples each time called.\"\n",
    "assert sample_real_data(13).shape == (13, 2)\n",
    "assert sample_real_data(2000).shape == (2000, 2), \"Forgot to sample with replacement?\"\n",
    "print(\"Looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot a sample of training data.** Call your *sample_real_data* function to plot 100 training samples. Your plot should look like\n",
    "![image](img/sample_real_data_uniform.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'sample of real data $x_{i}$')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAEKCAYAAADw9/tHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUn0lEQVR4nO3de7BdZX3G8e+Ti0kGDiZKNJeTEFtNTAQGpim2Q+ol5JSLNIy2TtV6aTGTsZoKjRRFHMWpjthMU23xUhqrTgUvU6SKbZCDkbFpRc1NJAnJIB4kgUgciYmYREJ+/WPvnS7O2vvsy1r7rH15PjNnZl/Wete7d7Kf/a73ffd6FRGYmSVNKLoCZtZ5HAxmluJgMLMUB4OZpTgYzCzFwWBmKQ4GM0txMJhZioOhC0kakbSiDeUukrRd0hFJ78y7/CrHa/h1SPqcpA+1u05W4mCwpGuBeyJiICL+sejKtKpdwdlPHAyWdBaws5ENJU1qc12sQA6GFkh6t6T95Sb3HkkXlR9/j6Qflx/fJenViX1GJP2NpPskPSnpM5KeL2ljefu7Jc0Ytf115XKekPRZSVNr1GeOpNskHZT0k7FOAyQtlnSPpEOSdkpaWX58E/BK4CZJv5K0sMq+I+XXfh/wpKRJ9Y491ntS5z0+X9K28n5fBqaOer5quZL+DZgP3FF+Hdc2Ww9Jfyfp9sT9dZK+JWlyI3XvCRHhvyb+gEXAI8Cc8v0FwG+Xb78WmEMpcP8UeBKYXX5uBLgXeD4wF3gc2AacD0wBNgEfSBxnBLgfmAc8B/gf4EOJ51aUb08AtgLvB54F/BbwEHBxlbpPBh4E3lvedjlwBFhUfv4eYNUYr30E2FGu07RGjt3Ae7KiynGeBTwM/HW5zn8CPFV5/a2UO9b2VY7/XOAQcB7wNuBHwLOL/r83rv/Pi65At/0BLyx/qFcAk+tsuwO4onx7BPizxHO3AZ9K3P8r4D8S90eAtyXuXwb8OPFcJRheCvx01HGvAz5bpT5/ABwAJiQe+yJwQ/l2I8FwZeJ+w8ce4z2pFgwvAx4FlHjsf5PB0Eq5tbav8fwNwH3lgJqXePztwMKi/x+2+8/niU2KiAclXU3pP85LJH0TWBsRj0p6M7CWUisC4HTgzMTuP0vcPlrl/umjDvdI4vbDlL7xRjsLmCPpUOKxicB/V9l2DvBIRJwcVe7cKtvWkqxT3WM38J5UMwfYH+VPYqKepzRbbgv12A58gFKYn3rNEfHJOnXvCe5jaEFE3BoRyyh9MAL4qKSzgH8B1gDPjYjplE4FlOFQ8xK351P6Fh3tEeAnETE98TcQEZdV2fZRYJ6k5L/7fGB/E3VKfljHPHaG9+QxYK6k5HbzKzcaKPcZFxlpth6SzgE+BXweuHLUc9UCt+c4GJpUHutfLmkKcIzSN/3TwGmU/kMeLG/3F8DZGQ/3DkmDkp5DqV/gy1W2+T5wuNwpOE3SRElnS/rdKtt+j9K59bWSJkt6BfBHwJdarF+9Y7f6nnwXOAG8s9zB+RrggsTz9cr9GaX+jka3P0XSXOAOSn0LbwfOKb9PSDqT0mlkz3MwNG8KcCPwc0rn688D3hsRu4C/p/Sf+mfAOZQ6DLO4FbiLUofeQ0Bqgk9EPE3pw30e8JNyvTYAz66y7W+AlcCl5e0+Cbw5Ih5opXL1jt3qe1Ku52uAPweeoNRZ+NXE8/XK/QjwvvLIyzWN1kPSGcB/Aesj4usR8WtgHfDh8ibnUup36Hl65mmcdQpJI5Q6Au8uui5WUu5bejgibq+7cZdzi8GscefQJy2G3EYlJE0EtlDqTb48r3LNOkVEvLXoOoyXPIcrrwJ2A2fkWGbfiogFRdfB+lcupxKSBoFXUep4MrMul1eL4WOUfpk3UGsDSauB1QCnnXba77z4xS/O6dBm1qitW7f+PCJm1tsuczBIuhx4PCK2VsZ7q4mIm4GbAZYuXRpbtmzJemgza5Kkh+tvlc+pxIXAyvLw2peA5ZK+kEO5ZlaQzMEQEddFxGC5s+x1wKaIeGPmmplZYTyPwcxScv11ZUTcQ+mnu2bWxdxiMLMUB4OZpTgYzCzFwWBmKQ4GM0txMJhZioPBzFIcDGaW4mAwsxQHg5mlOBjMLMXBYGYpDgYzS3EwmFmKg8HMUhwMZpbiYDCzFAeDmaVkDgZJUyV9X9IPJe2U9ME8KmZmxcnjmo/HgeUR8StJk4HNkjZGxL05lG1mBcgcDBERwK/KdyeX/yJruWZWnLzWrpwoaQfwODAcEd/Lo1wzK0YuwRART0fEecAgcIGks0dvI2m1pC2Sthw8eDCPw5pZm+Q6KhERhyitK3FJledujoilEbF05sy6a2qaWYHyGJWYKWl6+fY0YAXwQNZyzaw4eYxKzAY+L2kipaD5SkR8I4dyzawgeYxK3Aecn0NdzKxDeOajmaU4GMwsxcFgZikOBjNLcTCYWYqDwcxSHAxmluJgMLMUB4OZpTgYzCzFwWBmKQ4GM0txMJhZioPBzFIcDGaW4mAwsxQHg5mlOBjMLMXBYGYpeVwlep6kb0vaXV678qo8KmZmxcnjKtEngHdFxDZJA8BWScMRsSuHss2sAJlbDBHxWERsK98+AuwG5mYt18yKk2sfg6QFlC4ln1q70kvUmXWP3IJB0unAbcDVEXF49PNeos6se+S12vVkSqFwS0R8NY8yzaw4eYxKCPgMsDsi1mevkpkVLY8Ww4XAm4DlknaU/y7LoVwzK0gea1duBpRDXcysQ3jmo5mlOBjMLMXBYGYpDgYzS3EwmFmKg8HMUhwMZpbiYDCzFAeDmaU4GMwsxcFgZikOBjNLcTCYWYqDwcxSHAxmluJgMLMUB4OZpTgYzCwlr6tE/6ukxyXdn0d5ZlasvFoMnwMuyaksMytYLsEQEd8BfpFHWWZWvHHrY+jWJeqGdx3g0o9/h+FdBzqqLLN2Grdg6NYl6tYP72X3Y0dYP7y3o8oyayePSlSR/GZfO7SQxbMHWDu0MHO5eZZl1k6ZF5zpRclv9o1XvYyhJbOaLmN41wHWD+9l7dDCU/sPLZnVUllm4y2v4covAt8FFknaJ+mteZRblDy+2SvhsubW7e5TsK6T16jE6yNidkRMjojBiPhMHuXmpdlOv6Els1puKVSsHVrIlEkTOH7ipPsUrOv0/KnE8K4D/OUXtnHiZPDBO3Y19WGvnA4sXzSTTXsOPuO0oBEzB6YQEe5TsK7T88GwfngvJ04GABHR9L67HzvCQwefPPXN32gwrB/ey74njrJ49oD7Fazr9PyoxNqhhcydPpXBGdO4YeVLmt538ewBVi1b0HSfQ71+Cs9psE6mZr9F87B06dLYsmXLuB+3nmojCe0qv9IaWTx7gI1XvSz3Y5lVI2lrRCytt13PtxiakccEpLFaApXyP3jHLg4ffYrBGdPc/2Adqa+CoV7zvdVhymS5Y4VLpfyIYP+hYwxMneT+B+tIfRUM9VoEzQxT1gqDscKlUv4NK1/iGZDW0fqqj6HZPoSxtr/049851UdQ6TNoV9+EWV4a7WPo+eHKpGanJCdbAsn9hncd4MixE8ydPvVUGDQbCO3u6DTLoq9OJaoZq9+h1mlBZY7CGdMmt/yh9i8trZP1fTCM9QGt1eeQx28p/EtL62R9HwytfEDH6qSs1QIZ/fjQklksXzSTNbduZ92du7O9CLOc9VXnYztV+gwOH32K/YeOpSYuJTsrK48vet9Gjp84yZRJE9jzoUuLqrr1EXc+tlG1H1dVTkkGZ0x7RgskuS3wjJbJqmUL2LB5hFXLFhTxMsxq6vkWQzt6/yvf/pWfVY81ZFmtpWBWFE+JLmtH73+1H1e1s6PSbLy5xVCATqyT9Qe3GHLQ6AhDszyHwTpdXtd8vETSHkkPSnpPHmXmJcuHsNa+WT/YydMLX5fBOlHmYJA0EfgEcCmwBHi9pCVZy81LlnP8Wvtm7TdI9ke49WCdKHMfg6TfB26IiIvL968DiIiP1NqnU+YxdMK5fifUwfrHeM5jmAs8kri/D3hplQqtBlYDzJ8/P4fDZlfrR1LjyWtNWCfKo49BVR5LNUM6cYm6WqcEPu+3fpdHMOwD5iXuDwKP5lBu21WbezC86wBrbt3elvN+B451izyC4QfAiyS9QNKzgNcBX8+h3EKsH9576vcLeU9KckejdYvMwRARJ4A1wDeB3cBXImJn1nKLUjm9uOkN5+d+7u9ZkNYten7mYy2NjAZ4xMB6jWc+1tFIs77Vpr/7Eqzb9W0wNNKsb7Xp774E63Z9eyrRTj4FsU7lC7UUyJOWrNv17amE+wHMauurYGh0KTmzftdXwVAJgzW3bmf5opmFzilYd+duFr1vo68QbR2pr4Jh7dDCU9dp3LTnYMPrVLbDhs0jHD9xkg2bRwo5vtlY+ioYhpbM4qY3nN8RP5xatWwBUyZN8BWirSN5uLJs9NWcWx1yHGs/D2Na0TzzsY5kC2F41wEOH32KwRnTTrUkWu2cHGs/d3hat+jbYEh+SNcP72X/oWMMTJ106pu81VmPY+3nH1FZt+jbU4lksx5wE9/6gmc+1jF6dqIDwez/9e2pREWroxGV/dbdubvh/T3b0rpFXwVDtQ9m1k7GDZtHGt7fnY/WLfoqGKp9MLN2Mq5atoDBGdM4fPSpuitWeaEZ6xZ91fnYrnkEydWvk5eEG2ula6+CbUUYl3kMkl4raaekk5LqHqxotVakzio51brR1oiHLq2TZWoxSFoMnAT+GbgmIhpqBnTCcGUrPKvRut24tBgiYndE7MlSRlFaOccf3UeRLKNdrRGzIoxb56Ok1ZK2SNpy8ODB8TpsTa2MEIxu/nuUwXpV3WCQdLek+6v8XdHMgTptibqsy9NV+31FKzw6YZ2o7szHiFgxHhUZb7WuyzjWQrejWwj7Dx1j8eyBlk8fKsvhVTotfRpinaKv5jE0otGRhDxGFdq5HJ5ZFllHJV4N/BMwEzgE7IiIi+vt162jEnnzSIaNt0ZHJfpqgpNZv/OFWpqQ9YdU7ji0XuNgoD1XaxredYALb/wWyz66ycFhXcfBQHuu1lS5KtS+J456noN1nb69UEtStaHLRjoGx1qKbu3QQt797z/kyPGnWb6o+HkbZs1wi2GUSr/BDV/fmWlW49CSWTz/2dN46ulg057iZ3qaNcPBMEql30BS5nkK/gWldSufSoyydmhhbnMLvOq1dSsHwyitfpg9Wcl6iU8lEmrNS2hkvkJy6LLa9sO7DrDso5u48MZvefjSOp6DIaHWvIRG5jkk+xOqbb9+eC/7njjK/kPHPHxpHc/BkFCrs3D5oplMmTRhzGHH5IVaqpWzdmghgzOmMXf6VHdGWsfzbyUakLxwa56dk2bjzb+VaFG1/oFki8FXbbJ+4GAYpdoHf9Oegxw/cZJNew56boL1hb4MhtGtguT9Wv0Dlcd80VfrB33ZxzB6sRcv/mL9wn0MYxjdKvDpgdkz9WWLoVN4tqSNt/Faom6dpAck3SfpdknTs5RXlKKuxOQRDutUWU8lhoGzI+JcYC9wXfYqtU+tAKj3Aa3st+7O3af2zyNMKpOeqq2UbVakrEvU3RURJ8p37wUGs1epfWoFQL3l6Sv7bdg8cmr/epd1ayQ0hpbMYmDqJE+Tto6TZ+fjlcDGWk92whJ1tToZk0OQ1T7wlf1WLVvQ0LoSzZwiuOPTOlHdzkdJdwPVesauj4ivlbe5HlgKvCYa6M3s5M7HPDoE3alonWrc1pWQ9BbgbcBFEfHrRvbp5GAw62WNBkOmC7VIugR4N/DyRkPBzDpf1j6Gm4ABYFjSDkmfzqFOZlawTC2GiHhhXhUxs87Rl1OizWxsDgYzS3EwmFmKg8HMUhwMZpbiYDCzFAeDmaU4GMwsxcFgZikOBjNLcTCYWYqDwcxSHAxmluJgMLMUB4OZpTgYzCzFwWBmKQ4GM0vJukTd35aXp9sh6S5Jc/KqmJkVJ2uLYV1EnBsR5wHfAN6fQ53MrGBZl6g7nLh7GjD+S2ebWe4yXSUaQNKHgTcDvwRemblGZla4ui0GSXdLur/K3xUAEXF9RMwDbgHWjFFO4WtXmlljMi9Rd6og6SzgPyPi7Hrbeok6s2I0ukRd1lGJFyXurgQeyFKemXWGrH0MN0paBJwEHqa0uK2ZdbmsS9T9cV4VMbPO4ZmPZpbiYDCzFAeDmaU4GMwsxcFgZikOBjNLcTCYWYqDwcxSHAxmluJgMLMUB4OZpTgYzCzFwWBmKQ4GM0txMJhZioPBzFIcDGaW4mAwsxQHg5ml5BIMkq6RFJLOzKM8MytW5mCQNA8YAn6avTpm1gnyaDH8A3AtXrfSrGdkuny8pJXA/oj4oaR6264GVpfvHpd0f5Zjd7gzgZ8XXYk26uXX18uvDWBRIxvVXaJO0t3ArCpPXQ+8F/jDiPilpBFgaUTUfVMlbWlkmaxu5dfXvXr5tUHjr69uiyEiVtQ4wDnAC4BKa2EQ2Cbpgog40GR9zayDtHwqERE/Ap5Xud9Mi8HMOltR8xhuLui448Wvr3v18muDBl9f3T4GM+s/nvloZikOBjNLKTwYenE6taR1kh6QdJ+k2yVNL7pOeZB0iaQ9kh6U9J6i65MnSfMkfVvSbkk7JV1VdJ3yJmmipO2SvlFv20KDoYenUw8DZ0fEucBe4LqC65OZpInAJ4BLgSXA6yUtKbZWuToBvCsiFgO/B7yjx14fwFXA7kY2LLrF0JPTqSPirog4Ub57L6U5Ht3uAuDBiHgoIn4DfAm4ouA65SYiHouIbeXbRyh9gOYWW6v8SBoEXgVsaGT7woIhOZ26qDqMkyuBjUVXIgdzgUcS9/fRQx+cJEkLgPOB7xVbk1x9jNKX8MlGNs70W4l6GplO3c7jt9NYry0ivlbe5npKTdRbxrNubVLtxzA91dIDkHQ6cBtwdUQcLro+eZB0OfB4RGyV9IpG9mlrMPTydOpar61C0luAy4GLojcmi+wD5iXuDwKPFlSXtpA0mVIo3BIRXy26Pjm6EFgp6TJgKnCGpC9ExBtr7dARE5x6bTq1pEuA9cDLI+Jg0fXJg6RJlDpSLwL2Az8A3hAROwutWE5U+ob6PPCLiLi66Pq0S7nFcE1EXD7WdkV3Pvaqm4ABYFjSDkmfLrpCWZU7U9cA36TUMfeVXgmFsguBNwHLy/9mO8rfsH2pI1oMZtZZ3GIwsxQHg5mlOBjMLMXBYGYpDgYzS3EwmFmKg8HMUv4Ph6fRUpx8iv8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(0)  # Make cell output reproducible\n",
    "\n",
    "# Your plotting code here. Aim for 5-7 lines.\n",
    "#print(sample_real_data(100).shape)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.axis([-4, 4, -4, 4])\n",
    "plt.xticks(np.arange(-4,5,step=2))\n",
    "plt.scatter(sample_real_data(100)[:,0],sample_real_data(100)[:,1],marker='.',s = 10)\n",
    "plt.title(r'sample of real data $x_{i}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 1.2 &mdash; Create a source of noise $\\mathbf{z}$\n",
    "\n",
    "Recall that a GAN starts from a value $\\mathbf{z}$ that was sampled from a standard random distribution (*e.g.* uniform, normal) and then transforms it into a new data point $\\mathbf{\\hat{x}} = G(\\mathbf{z})$.\n",
    "\n",
    "**Implement the *sample_fake_noise* function.** Use the **[torch.rand](https://pytorch.org/docs/stable/torch.html?highlight=rand#torch.rand)** function to generate random samples $\\mathbf{z} \\sim U(-\\frac{1}{2}, \\frac{1}{2})^2$, *i.e.* in the 2-dimensional unit square centered at the origin where $z_1,z_2 \\in [-\\frac{1}{2}, \\frac{1}{2}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_fake_noise(batch_size):\n",
    "    \"\"\"\n",
    "    Returns batch_size samples of 2-dimensional noise on the unit inverval [-0.5, 0.5].\n",
    "    The returned tensor has shape (batch_size, 2).\n",
    "    \"\"\"\n",
    "    # Your code here. Aim for 1-2 lines.\n",
    "    return (torch.rand(batch_size,2)).uniform_(-0.5,0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your answer** by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks good!\n"
     ]
    }
   ],
   "source": [
    "_Z = sample_fake_noise(5)\n",
    "assert isinstance(_Z, torch.FloatTensor), \"Expected a tensor of dtype float32\"\n",
    "assert _Z.shape == (5, 2), \"Expected noise to have shape (batch_size, 2)\"\n",
    "assert torch.all((_Z >= -0.5) & (_Z <= 0.5)), \"Expected uniform distribution centered at 0\"\n",
    "print(\"Looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot a sample of your noise.** Your plot should look like\n",
    "![image](img/sample_noise_uniform.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'sample of real data $x_{i}$')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(1)  # Make cell output reproducible\n",
    "\n",
    "# Your plotting code here. Aim for 5-7 lines.\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.axis([-4, 4, -4, 4])\n",
    "plt.xticks(np.arange(-4,5,step=2))\n",
    "plt.scatter(sample_fake_noise(100)[:,0],sample_fake_noise(100)[:,1],marker='.',s = 10 ,c='grey')\n",
    "plt.title(r'sample of real data $x_{i}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 1.3 &mdash; Create an untrained GAN generator\n",
    "\n",
    "You are asked to define a generator model in PyTorch. Your generator $G:\\mathbb{R}^2 \\rightarrow \\mathbb{R}^2$ should be a linear transformation, taking the form $G(\\mathbf{z}) = \\mathbf{W} \\mathbf{z} + \\mathbf{b}$ for some trainable parameters $\\mathbf{W}, \\mathbf{b}$.\n",
    "\n",
    "**Write a few lines of code** to create a *generator* variable that refers to a PyTorch module implementing the the above transformation. You can use the built-in transformations provided by PyTorch, so this is no different than in Lab 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(5)  # Make cell output reproducible\n",
    "\n",
    "# Your code here. Aim for 1-3 lines.\n",
    "generator = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your answer** by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks good!\n"
     ]
    }
   ],
   "source": [
    "assert \"generator\" in globals(), \"Expected generator variable to be defined.\"\n",
    "assert isinstance(generator, torch.nn.Module), \"Generator should be a torch module of some type.\"\n",
    "assert generator(torch.zeros((5, 2))).shape == (5, 2), \"Output seems to be wrong shape/dimension.\"\n",
    "print(\"Looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implement the *sample_fake_data* function.** Use your *sample_fake_noise* function from earlier. Obviously your function should make use of the *generator* variable you defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_fake_data(batch_size):\n",
    "    \"\"\"\n",
    "    Returns batch_size samples from the current generator.\n",
    "    The returned tensor has shape (batch_size, 2).\n",
    "    \"\"\"\n",
    "    # Your code here. Aim for 1-2 lines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot a sample of fake data** alongside a sample of noise. Recall that your generator has weights $\\mathbf{w}$ that are initialized to be small random values, so you should see some arbitrary transformation like this:\n",
    "![image](img/sample_fake_data_uniform.png)\n",
    "\n",
    "*Note.* When you try to plot a PyTorch tensor, Matplotlib asks the tensor to convert itself to a Numpy array. However, any tensor that is the output of a PyTorch \"Module\" will have gradient tracking enabled (the tensor will be \"attached\" to a compute graph). You may need to call the **[detach](   https://pytorch.org/docs/1.2.0/tensors.html?highlight=detach#torch.Tensor.detach)** method on such tensors before you can plot with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your plotting code here. Aim for 7-9 lines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 1.4 &mdash; Create an untrained GAN discriminator\n",
    "\n",
    "You are asked to define a discriminator model in PyTorch. Your discriminator $D:\\mathbb{R}^2 \\rightarrow \\mathbb{R}$ should also be a linear transformation, taking the form $D(\\mathbf{x}) = \\mathbf{W} \\mathbf{x} + \\mathbf{b}$ for some trainable parameters $\\mathbf{W}, \\mathbf{b}$. The sigmoid for binary classification will be applied later.\n",
    "\n",
    "**Write a few lines of code** to create a *discriminator* variable that refers to a PyTorch module implementing the the above transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(5)  # Make cell output reproducible\n",
    "\n",
    "# Your code here. Aim for 1-3 lines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your answer** by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"discriminator\" in globals(), \"Expected discriminator variable to be defined.\"\n",
    "assert isinstance(discriminator, torch.nn.Module), \"Discriminator should be a torch module.\"\n",
    "assert discriminator(torch.zeros((5, 2))).shape == (5, 1), \"Output seems to be wrong shape/dimension.\"\n",
    "print(\"Looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 1.5 &mdash; Train your GAN on the synthetic training data\n",
    "\n",
    "The GAN training objective includes:\n",
    "* a binary cross entropy loss applied to the output of the discriminator\n",
    "* a stochastic gradient descent optimizer for the discriminator weights\n",
    "* a stochastic gradient descent optimizer for the generator weights\n",
    "* a function to do forward and backpropagation for the discriminator\n",
    "* a function to do forward and backpropagation for the generator\n",
    "\n",
    "**Run the code cell below** to set up these elements so that training is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "discriminator_optim = torch.optim.SGD(discriminator.parameters(), lr=0.01, momentum=0.8)\n",
    "generator_optim     = torch.optim.SGD(generator.parameters(),     lr=0.01, momentum=0.8)\n",
    "\n",
    "# Use 100 samples of real and fake data per update.\n",
    "batch_size = 100\n",
    "\n",
    "# Create vectors to act as binary training targets\n",
    "y_real = torch.ones((batch_size, 1))   # 1 means \"this data point is real\"\n",
    "y_fake = torch.zeros((batch_size, 1))  # 0 means \"this data point is fake\"\n",
    "\n",
    "def update_discriminator():\n",
    "    discriminator.zero_grad()         # Get ready to accumulate gradient for discriminator weights.\n",
    "    \n",
    "    X = sample_real_data(batch_size)  # Sample real data.\n",
    "    y = discriminator(X)              # Predict real or fake.\n",
    "    l = loss(y, y_real)               # Discriminator wants to predict \"real\" for these cases.\n",
    "    l.backward()                      # Accumulate discriminator gradient.\n",
    "    \n",
    "    X = sample_fake_data(batch_size).detach()  # Sample fake data. (Detach so no generator gradient.)\n",
    "    y = discriminator(X)                       # Predict real or fake.\n",
    "    l = loss(y, y_fake)                        # Discriminator Wants to predict \"fake\" for these.\n",
    "    l.backward()                               # Accumulate discriminator gradient.\n",
    "    \n",
    "    discriminator_optim.step()        # Use gradient to improve the discriminator!\n",
    "\n",
    "def update_generator():\n",
    "    generator.zero_grad()             # Get ready to accumulate gradient for generator weights.\n",
    "    \n",
    "    X = sample_fake_data(batch_size)  # Sample fake data. (Don't detach, so backprop to generator.)\n",
    "    y = discriminator(X)              # Predict real or fake.\n",
    "    l = loss(y, y_real)               # Generator wants discriminator to predict \"real\" for these.\n",
    "    l.backward()                      # Accumulate generator gradient, backprop through discriminator!\n",
    "    \n",
    "    generator_optim.step()            # Use gradient to improve generator!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add plotting code to the GAN training loop below.** You should use the \"plot updating\" technique demonstrated at the start of this lab. If you only ran the training loop for 1 step the first plot should look like this:\n",
    "![image](img/gan_training_linear_epoch0001.png)\n",
    "After 500 steps your plot should look more like this:\n",
    "![image](img/gan_training_linear_epoch0500.png)\n",
    "You can re-run the code cell to continue training an additional 500 steps, from whatever the most recent parameters were. If you want to reset the training, you must go back and re-run the code cell defining *generator* and all subsequent code cells.\n",
    "\n",
    "*Tip 1:* Plotting is slow, so if you want to speed up training, consider only updating the plot every 10th step. You can use the module `%` operator to do this.\n",
    "\n",
    "*Tip 2:* If you wish the points in your plot to remain consistent, rather than being a different random sample each time, you can use the *torch.manual_seed* function immediately prior to plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 2000\n",
    "for step in range(1, num_steps+1):\n",
    "    update_discriminator()\n",
    "    update_generator()\n",
    "                \n",
    "    if step == 1 or (step % 10 == 0):\n",
    "        plt.gca().cla()\n",
    "        \n",
    "        torch.manual_seed(0)  # Resample the same data each time\n",
    "        \n",
    "        # Your plotting code here. Aim for 8-12 lines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we generate both the training data $\\mathbf{x}_i$ and the random noise $\\mathbf{z}$ from a uniform distribution, we know that a linear generator $G$ is capable, in principle, of fitting to this data.\n",
    "\n",
    "However, given that the linear discriminator $D$ is only capable of a linear decision boundary in feature space, you may observe that the best it can do is to center the fake points within the cloud of blue points. To get a tighter fit to the data, a more powerful discriminator is required.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 2. Modify your generator and discriminator architectures\n",
    "\n",
    "Exercise 2.1&ndash;2.2 ask you to try more sophisticated generator and discriminator architectures, to understand how they impact the training dynamics and the complexity of the distribution.\n",
    "\n",
    "Rather than writing new code, you will have to go back to Exercise 1 and edit your existing answers. *Remember to always re-run all code cells that follow your edit.* Otherwise some of your code cells may be keeping references to old versions of your objects (old generator, old discriminator, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 2.1 &mdash; Use quadratic features in your discriminator\n",
    "\n",
    "You should learn how to define your own PyTorch module, as a class inherited from **[torch.nn.Module](https://pytorch.org/docs/1.2.0/nn.html#torch.nn.Module)**.\n",
    "\n",
    "Go back to Exercise 1.4 and define a new custom module class called *QuadraticFeatures*. The purpose is to transform data $\\mathbf{x}=\\begin{bmatrix}x_1 & x_2 \\end{bmatrix}$ into a 5-dimensional feature space $\\mathbf{\\phi}(\\mathbf{x})=\\begin{bmatrix} x_1 & x_2 & \\frac{1}{10}x_1^2 & \\frac{1}{10}x_2^2 & \\frac{1}{10}x_1 x_2\\end{bmatrix}$ for classification. The discriminator can thus produce non-linear decision boundaries in the original data space, and have more discriminative power.\n",
    "\n",
    "*Tip:* The **[torch.stack](https://pytorch.org/docs/1.2.0/torch.html?highlight=stack#torch.stack)** function may be convenient.\n",
    "\n",
    "After re-running all the necessary code cells (including the code cell resetting the *generator*) and training for many steps, you should see a fit more like this:\n",
    "\n",
    "![image](img/gan_training_quadratic_epoch5000.png)\n",
    "\n",
    "(As for the $\\frac{1}{10}$ coefficients, remember what happens to gradient-based training if you don't scale down the quadratic features!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Exercise 2.2 &mdash; Use a ReLU layer in your discriminator\n",
    "\n",
    "Go back to Exercise 1.4 and, instead of quadratic features, use a discriminator that is a 2-50-1 ReLU neural network. In other words, add a hidden layer with 50 ReLU units to your discriminator.\n",
    "\n",
    "After re-running all the necessary code cells, you should see a fit more like this:\n",
    "\n",
    "![image](img/gan_training_relu_epoch2000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-bottom: 3px solid black;\"></div>\n",
    "\n",
    "### Other exercises\n",
    "\n",
    "* Try adding hidden layers to your generator, too!\n",
    "* Try creating multi-modal training data!\n",
    "* Try training a GAN on MNIST digits! (may take time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
